# EstimaciÃ³n de Calificaciones y PredicciÃ³n de AprobaciÃ³n de Estudiantes

Este proyecto tiene como objetivo desarrollar dos modelos de Machine Learning para predecir el rendimiento acadÃ©mico de los estudiantes. Los modelos son:

1. **Modelo de predicciÃ³n de calificaciones**: Predice la nota final de un estudiante.
2. **Modelo de predicciÃ³n de aprobaciÃ³n**: Predice si un estudiante aprobarÃ¡ el curso (nota > 60).

---

## ğŸ“ DescripciÃ³n del Proyecto

Trabajamos con un conjunto de datos que contiene informaciÃ³n acadÃ©mica y personal de estudiantes. El proyecto estÃ¡ dividido en las siguientes etapas:

1. **Limpieza de datos**
    Cargar el dataset, entender los datos y corregir todos los errores.

2. **AnÃ¡lisis Exploratorio de Datos (EDA)**  
   IdentificaciÃ³n de patrones y relaciones.

3. **Preprocesamiento de Datos**  
   CodificaciÃ³n de variables categÃ³ricas y escalado de variables numÃ©ricas.

4. **Entrenamiento de Modelos**  
   Entrenar diferentes modelos, evaluarlos y afinar los mejores 

5. **ImplementaciÃ³n con FastAPI**  
   ExposiciÃ³n de ambos modelos como una API accesible mediante peticiones HTTP POST.

6. **DockerizaciÃ³n del Proyecto**  
   El proyecto se ha dockerizado para facilitar su despliegue y portabilidad en cualquier entorno.

---

## ğŸ“‚ Estructura del Proyecto


ğŸ“¦ 
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset_estudiantes.csv
â”‚   â”œâ”€â”€ clean_dataset_estudiantes.csv
â”‚   â””â”€â”€ preprocessed_dataset.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ regression_model.pkl
â”‚   â”œâ”€â”€ classification_model.pkl
â”‚   â””â”€â”€ standard_scaler.pkl
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Cleaning.ipynb
â”‚   â”œâ”€â”€ 02_EDA.ipynb
â”‚   â”œâ”€â”€ 03_Preprocessing.ipynb
â”‚   â””â”€â”€ 04_Predictive_models.ipynb
â”œâ”€â”€ main.py                     # API con FastAPI
â”œâ”€â”€ functions.py               # Funciones de preprocesamiento
â”œâ”€â”€ requirements.txt           # Dependencias del proyecto
â”œâ”€â”€ Dockerfile                 # Dockerfile para empaquetar la API
â””â”€â”€ README.md                  # DocumentaciÃ³n del proyecto

---

## ğŸ“¥ Requisitos

Este proyecto requiere las siguientes librerÃ­as de Python. Puedes instalar todas las dependencias necesarias ejecutando el siguiente comando:

``pip install -r requirements.txt``

Algunas de las dependencias principales incluyen:

- FastAPI: Framework para crear APIs rÃ¡pidas.

- Uvicorn: Servidor ASGI para ejecutar FastAPI.

- pandas: Para la manipulaciÃ³n de datos.

- numpy: Para operaciones matemÃ¡ticas.

- scikit-learn: Para entrenar y evaluar los modelos de Machine Learning.

- matplotlib y seaborn: Para visualizaciÃ³n de datos.

---

## ğŸš€ Uso de la API

Una vez ejecutada la API, puedes acceder a:

- POST /predict/grade â†’ Predice la calificaciÃ³n final del estudiante.

- POST /predict/pass â†’ Predice si el estudiante aprueba o no.

## ğŸ§ª Ejemplo de entrada JSON:

{
  "horas_estudio_semanal": 5,
  "nota_anterior": 65,
  "tasa_asistencia": 90,
  "horas_sueno": 7,
  "edad": 19,
  "nivel_dificultad": "medio",
  "tiene_tutor": "sÃ­",
  "estilo_aprendizaje": "visual",
  "horario_estudio_preferido": "noche"
}

---

# ğŸ³ Docker

### ConstrucciÃ³n de la imagen

docker build -t student-api .

### EjecuciÃ³n del contenedor

docker run -p 8000:8000 student-api

### Acceso a la documentaciÃ³n

Una vez desplegado, accede a la documentaciÃ³n interactiva de la API en:
http://localhost:8000/docs

---

## ğŸ“Š Resultados y conclusiones

### Conclusiones RegresiÃ³n:
El modelo Lasso ha mostrado un desempeÃ±o mÃ¡s equilibrado, con un RÂ² cercano al 34-35% tanto en el conjunto de entrenamiento como en el de prueba. Esto indica que el modelo generaliza bien sin sobreajustarse. AdemÃ¡s, Lasso presenta un menor error cuadrÃ¡tico medio (RMSE), lo que sugiere una mayor precisiÃ³n en las predicciones.

Por estos motivos, se ha elegido el modelo Lasso como la opciÃ³n mÃ¡s adecuada para este caso. Se realizarÃ¡ el entrenamiento final y se guardarÃ¡ el modelo.

### Conclusiones Finales ClasificaciÃ³n:
Aunque la precisiÃ³n de la regresiÃ³n logÃ­stica es la mÃ¡s alta, esto puede ser engaÃ±oso si no consideramos otras mÃ©tricas clave como el recall y el F1-Score. La precisiÃ³n solo mide la proporciÃ³n de predicciones correctas entre las predicciones positivas, pero no toma en cuenta los falsos negativos, es decir, las instancias que el modelo no predice correctamente.

El **Random Forest** ofrece un mejor equilibrio entre precisiÃ³n y recall, lo cual lo convierte en la opciÃ³n mÃ¡s robusta. Este modelo serÃ¡ guardado para su uso posterior.


## ğŸ“Œ PrÃ³ximos Pasos

- **OptimizaciÃ³n de Modelos**: Mejorar el rendimiento de los modelos mediante tÃ©cnicas como la selecciÃ³n de caracterÃ­sticas, optimizaciÃ³n de hiperparÃ¡metros y pruebas con otros algoritmos.
- **AmpliaciÃ³n del dataset**: Incluir mÃ¡s datos y/o caracterÃ­sticas relevantes para mejorar la capacidad predictiva.


## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Si deseas mejorar el proyecto, por favor abre un pull request o una issue.

## ğŸ‘¨â€ğŸ’» Autor

- Sergio Delgado
- sergiodelamp@gmail.com
- https://github.com/Sergiio02